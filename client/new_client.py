#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Pedestrian detection in drone videos - Fixed Version
×¢× ×—×™×‘×•×¨ ××©×•×¤×¨ ×œ××¤×” ×”×“×™× ××™×ª - ×œ×œ× ×©×’×™××•×ª
"""

import cv2
import numpy as np
import json
from pathlib import Path
import time
import requests
from datetime import datetime
from dataclasses import dataclass
import pandas as pd
from typing import List

# Try importing keras-retinanet
try:
    from keras_retinanet.models import load_model
    from keras_retinanet.utils.visualization import draw_box, label_color
    from keras_retinanet.utils.image import preprocess_image, resize_image

    RETINANET_AVAILABLE = True
    print("âœ… keras-retinanet is available")
except ImportError as e:
    print(f"âš ï¸  keras-retinanet not available: {e}")
    RETINANET_AVAILABLE = False

# ×”×’×“×¨×•×ª API
BASE_URL = "http://localhost:8080"
VIDEO_ENDPOINT = f"{BASE_URL}/insert_video/"
LOCATION_UPDATE_ENDPOINT = f"{BASE_URL}/update_location/"
STATS_ENDPOINT = f"{BASE_URL}/get_video_stats/"

# ×”×’×“×¨×•×ª ×•×™×“××•
video_path = "video/video1.mp4"

# ×”×’×“×¨×•×ª ×¢×™×‘×•×“
SKIP_FRAMES = 7
CONFIDENCE_THRESHOLD = 0.4


def check_server_connection():
    """×‘×“×™×§×ª ×—×™×‘×•×¨ ×œ×©×¨×ª"""
    try:
        response = requests.get(f"{BASE_URL}/", timeout=5)
        if response.status_code == 200:
            print("âœ… ×—×™×‘×•×¨ ×œ×©×¨×ª ×”×¦×œ×™×—")
            return True
        else:
            print(f"âš ï¸ ×©×¨×ª ××’×™×‘ ××‘×œ ×¢× ×©×’×™××”: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print(f"âŒ ×œ× × ×™×ª×Ÿ ×œ×”×ª×—×‘×¨ ×œ×©×¨×ª ×‘-{BASE_URL}")
        print("ğŸ’¡ ×•×“× ×©×”×©×¨×ª ×¨×¥ ×¢×œ localhost:8080")
        return False
    except requests.exceptions.Timeout:
        print("â±ï¸ ×–××Ÿ ×”×—×™×‘×•×¨ ×œ×©×¨×ª ×¤×’")
        return False


def get_server_stats():
    """×§×‘×œ×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ××”×©×¨×ª"""
    try:
        response = requests.get(STATS_ENDPOINT, timeout=10)
        if response.status_code == 200:
            stats = response.json()
            print(f"ğŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª ×©×¨×ª:")
            print(f"   ğŸ“ ×¡×”×´×› ×¨×©×•××•×ª: {stats.get('total_entries', 0)}")
            print(f"   ğŸ‘¥ ×¡×”×´×› ×× ×©×™× ×–×•×”×•: {stats.get('total_people_detected', 0)}")
            print(f"   ğŸ¬ ×•×™×“××•×™× ×™×™×—×•×“×™×™×: {stats.get('unique_videos', 0)}")
            print(f"   ğŸ“ ×¨×©×•××•×ª ×¢× ××™×§×•×: {stats.get('entries_with_location', 0)}")
            return stats
        else:
            print(f"âŒ ×©×’×™××” ×‘×§×‘×œ×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª: {response.status_code}")
            return None
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×—×™×‘×•×¨ ×œ×¡×˜×˜×™×¡×˜×™×§×•×ª: {e}")
        return None


def create_video_entry1(data):
    """×™×¦×™×¨×ª ×¨×©×•××ª ×•×™×“××• ×—×“×©×” ×¢× ×©×™×¤×•×¨×™×"""
    max_retries = 3
    retry_delay = 1

    for attempt in range(max_retries):
        try:
            response = requests.post(VIDEO_ENDPOINT, json=data, timeout=10)
            if response.status_code == 200:
                result = response.json()
                print(f"âœ… Frame {data['frame_number']}: × ×•×¡×£ ×‘×”×¦×œ×—×” (ID: {result.get('id')})")
                return True
            else:
                print(f"âŒ Frame {data['frame_number']}: ×©×’×™××” {response.status_code}")
                if attempt < max_retries - 1:
                    print(f"ğŸ”„ × ×™×¡×™×•×Ÿ ×—×•×–×¨ {attempt + 2}/{max_retries}...")
                    time.sleep(retry_delay)
                    retry_delay *= 2
        except requests.exceptions.ConnectionError:
            print(f"âŒ Frame {data['frame_number']}: ×©×’×™××ª ×—×™×‘×•×¨")
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
                retry_delay *= 2
        except requests.exceptions.Timeout:
            print(f"â±ï¸ Frame {data['frame_number']}: ×–××Ÿ ×”×‘×§×©×” ×¤×’")
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
        except Exception as e:
            print(f"âŒ Frame {data['frame_number']}: ×©×’×™××ª ×‘×§×©×” - {e}")
            break

    print(f"ğŸ’¥ Frame {data['frame_number']}: × ×›×©×œ ×œ××—×¨ {max_retries} × ×™×¡×™×•× ×•×ª")
    return False

def create_video_entry2(video_path: str, excel_path: str, model=None):
    """
    ×¤×•× ×§×¦×™×” ××—×ª ×©××‘×¦×¢×ª ××ª ×›×œ ×”×ª×”×œ×™×š:
    ×˜×¢×™× ×ª ×•×™×“××• + × ×ª×•× ×™ ××™×§×•× + ×–×™×”×•×™ ×× ×©×™× + ×©×œ×™×—×” ×¢× ××™×§×•× ×‘×¤×¢× ××—×ª ×œ×©×¨×ª
    """
    # ×¤×ª×™×—×ª ×•×™×“××•
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("âŒ ×œ× × ×™×ª×Ÿ ×œ×¤×ª×•×— ××ª ×”×•×™×“××•")
        return

    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f"ğŸ“½ï¸ FPS: {fps}, Total frames: {total_frames}")

    # ×˜×¢×Ÿ ××™×§×•× ×Ö¾Excel ×œ××™×œ×•×Ÿ
    try:
        df = pd.read_excel(excel_path)
        df['timestamp'] = df['timestamp'].astype(str).str.replace('s', '', regex=False).astype(float)
        df['frame_number'] = (df['timestamp'] * fps).astype(int)
        location_map = {
            int(row['frame_number']): {
                "height": float(row['altitude']),
                "longitude": float(row['longitude']),
                "latitude": float(row['latitude']),
            }
            for _, row in df.iterrows()
        }
        print(f"âœ… × ×˜×¢× ×• {len(location_map)} ×¤×¨×™×™××™× ×¢× ××™×§×•×")
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª Excel: {e}")
        location_map = {}

    # ×”×’×œ××™ (×œ××©×œ HOG)
    if model is None:
        hog = cv2.HOGDescriptor()
        hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())

    frame_count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        if frame_count % 7 != 0:
            continue

        # ×–×™×”×•×™ ×× ×©×™×
        if model is None:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            rects, _ = hog.detectMultiScale(gray, winStride=(4, 4), padding=(8, 8), scale=1.05)
            people_count = len(rects)
        else:
            # RetinaNet (×× ×§×™×™×)
            image = preprocess_image(frame.copy())
            image, scale = resize_image(image)
            boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))
            boxes /= scale
            people_count = sum(1 for score, label in zip(scores[0], labels[0]) if score > 0.4 and label == 0)

        # ×–××Ÿ ×•×ª×–××•×Ÿ
        timestamp_seconds = round(frame_count / fps, 2) if fps > 0 else frame_count
        now_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        # ××™×§×•× ××”-Excel
        location = location_map.get(frame_count, {
            "height": 0,
            "longitude": 0.0,
            "latitude": 0.0
        })

        payload = {
            "frame_number": frame_count,
            "timestamp": timestamp_seconds,
            "pedestrian_count": people_count,
            "time": now_time,
            "video_path": video_path,
            "height": location["height"],
            "longitude": location["longitude"],
            "latitude": location["latitude"]
        }

        try:
            res = requests.post(f"{BASE_URL}/insert_video/", json=payload)
            if res.status_code == 200:
                print(f"âœ… Frame {frame_count}: × ×©×œ×— ×¢× {people_count} ×× ×©×™× ×•××™×§×•× ({location['latitude']}, {location['longitude']})")
            else:
                print(f"âŒ ×©×’×™××” ×‘×©×œ×™×—×” ×œ×©×¨×ª: {res.status_code} - {res.text}")
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×‘×§×©×”: {e}")

    cap.release()
    cv2.destroyAllWindows()

def create_video_entry(video_path: str, excel_path: str, model=None):
    """
    ×˜×¢×™× ×ª ×•×™×“××• + × ×ª×•× ×™ ××™×§×•× + ×–×™×”×•×™ ×× ×©×™× + ×©×œ×™×—×” ×¢× ××™×§×•× ×”×§×¨×•×‘ ×‘×™×•×ª×¨ ×œ×›×œ ×¤×¨×™×™× ××“×•×’×
    """

    def find_closest_location(frame_number, location_map, max_distance=15):
        """×××ª×¨ ××ª ××™×§×•× ×”-GPS ×”×§×¨×•×‘ ×‘×™×•×ª×¨ ×œ×¤×¨×™×™×"""
        if not location_map:
            return {'height': 0, 'longitude': 0.0, 'latitude': 0.0}

        closest_frame = min(location_map.keys(), key=lambda x: abs(x - frame_number))
        if abs(closest_frame - frame_number) > max_distance:
            return {'height': 0, 'longitude': 0.0, 'latitude': 0.0}
        return location_map[closest_frame]

    # ×¤×ª×™×—×ª ×•×™×“××•
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("âŒ ×œ× × ×™×ª×Ÿ ×œ×¤×ª×•×— ××ª ×”×•×™×“××•")
        return

    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f"ğŸ“½ï¸ FPS: {fps}, Total frames: {total_frames}")

    # ×˜×¢×™× ×ª ××™×§×•× ××§×•×‘×¥ Excel
    try:
        df = pd.read_excel(excel_path)
        df['timestamp'] = df['timestamp'].astype(str).str.replace('s', '', regex=False).astype(float)
        df['frame_number'] = (df['timestamp'] * fps).astype(int)
        location_map = {
            int(row['frame_number']): {
                "height": float(row['altitude']),
                "longitude": float(row['longitude']),
                "latitude": float(row['latitude']),
            }
            for _, row in df.iterrows()
        }
        print(f"âœ… × ×˜×¢× ×• {len(location_map)} ×¤×¨×™×™××™× ×¢× ××™×§×•×")
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª Excel: {e}")
        location_map = {}

    # ×’×œ××™ ×‘×¨×™×¨×ª ××—×“×œ ×× ××™×Ÿ ××•×“×œ RetinaNet
    if model is None:
        hog = cv2.HOGDescriptor()
        hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())

    frame_count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        if frame_count % SKIP_FRAMES != 0:
            continue  # ×¨×§ ×›×œ N ×¤×¨×™×™××™×

        # ×–×™×”×•×™ ×× ×©×™×
        if model is None:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            rects, _ = hog.detectMultiScale(gray, winStride=(4, 4), padding=(8, 8), scale=1.05)
            people_count = len(rects)
        else:
            image = preprocess_image(frame.copy())
            image, scale = resize_image(image)
            boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))
            boxes /= scale
            people_count = sum(1 for score, label in zip(scores[0], labels[0]) if score > 0.4 and label == 0)

        # ×–××Ÿ
        timestamp_seconds = round(frame_count / fps, 2) if fps > 0 else frame_count
        now_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        # ×§×‘×œ×ª ××™×§×•× ×§×¨×•×‘
        location = find_closest_location(frame_count, location_map)

        payload = {
            "frame_number": frame_count,
            "timestamp": timestamp_seconds,
            "pedestrian_count": people_count,
            "time": now_time,
            "video_path": video_path,
            "height": location["height"],
            "longitude": location["longitude"],
            "latitude": location["latitude"]
        }

        try:
            res = requests.post(f"{BASE_URL}/insert_video/", json=payload)
            if res.status_code == 200:
                print(f"âœ… Frame {frame_count}: × ×©×œ×— ×¢× {people_count} ×× ×©×™× ×•××™×§×•× ({location['latitude']}, {location['longitude']})")
            else:
                print(f"âŒ ×©×’×™××” ×‘×©×œ×™×—×” ×œ×©×¨×ª: {res.status_code} - {res.text}")
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×‘×§×©×”: {e}")

    cap.release()
    cv2.destroyAllWindows()


def find_available_model():
    """×—×™×¤×•×© ××•×“×œ ×–××™×Ÿ ×‘××¢×¨×›×ª"""
    possible_paths = [
        "snapshots/resnet50_csv_08_inference.h5",
        "models/resnet50_csv_08_inference.h5",
        "weights/resnet50_csv_08_inference.h5",
        "../models/resnet50_csv_08_inference.h5",
        "snapshots/resnet50_coco_best_v2.1.0.h5",
    ]

    print("ğŸ” ××—×¤×© ××•×“×œ×™× ×–××™× ×™×...")
    for path in possible_paths:
        if Path(path).exists():
            print(f"âœ… × ××¦× ××•×“×œ: {path}")
            return path

    # ×—×™×¤×•×© ×›×œ ×§×‘×¦×™ h5
    h5_files = list(Path(".").rglob("*.h5"))
    if h5_files:
        print("ğŸ“ ×§×‘×¦×™ h5 ×©× ××¦××•:")
        for i, file in enumerate(h5_files):
            size_mb = file.stat().st_size / (1024 * 1024)
            print(f"  {i + 1}. {file} ({size_mb:.1f} MB)")
            if size_mb > 10:
                print(f"ğŸ¯ × ×‘×—×¨: {file}")
                return str(file)

    print("âŒ ×œ× × ××¦× ××•×“×œ ××ª××™×")
    return None


def create_simple_detector():
    """×™×¦×™×¨×ª ×’×œ××™ ×¤×©×•×˜ ×¢× HOG"""
    print("ğŸ”§ ×™×•×¦×¨ ×’×œ××™ ×¤×©×•×˜...")
    hog = cv2.HOGDescriptor()
    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
    return hog


def detect_with_hog(frame, hog_detector):
    """×–×™×”×•×™ ×× ×©×™× ×¢× HOG ×¢× ×ª×¦×•×’×” ×—×–×•×ª×™×ª ××©×•×¤×¨×ª"""
    try:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        (rects, weights) = hog_detector.detectMultiScale(
            gray, winStride=(4, 4), padding=(8, 8), scale=1.05, groupThreshold=2
        )

        display_frame = frame.copy()

        # ×¦×™×•×¨ ××œ×‘× ×™× ×¡×‘×™×‘ ×× ×©×™× ×©×–×•×”×•
        for i, (x, y, w, h) in enumerate(rects):
            confidence = weights[i] if i < len(weights) else 0.8

            # ×¦×‘×¢ ×œ×¤×™ ×¨××ª ×‘×™×˜×—×•×Ÿ
            if confidence > 0.8:
                color = (0, 255, 0)  # ×™×¨×•×§
            elif confidence > 0.5:
                color = (0, 255, 255)  # ×¦×”×•×‘
            else:
                color = (0, 165, 255)  # ×›×ª×•×

            cv2.rectangle(display_frame, (x, y), (x + w, y + h), color, 3)
            cv2.putText(display_frame, f"Person {confidence:.2f}",
                        (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

        # ×”×¦×’×ª ××™×“×¢ × ×•×¡×£ ×¢×œ ×”××¡×š
        info_text = [
            f"People Detected: {len(rects)}",
            f"Time: {datetime.now().strftime('%H:%M:%S')}",
            f"Frame Size: {frame.shape[1]}x{frame.shape[0]}"
        ]

        for i, text in enumerate(info_text):
            y_pos = 30 + (i * 25)
            cv2.putText(display_frame, text, (10, y_pos),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

        cv2.imshow('Drone Video - Live Detection', display_frame)
        cv2.waitKey(1)

        # ×™×¦×™×¨×ª ×¨×©×™××ª ×× ×©×™× ×©×–×•×”×•
        people = []
        for i, (x, y, w, h) in enumerate(rects):
            confidence = weights[i] if i < len(weights) else 0.8
            if confidence >= CONFIDENCE_THRESHOLD:
                people.append({
                    'bbox': [int(x), int(y), int(w), int(h)],
                    'confidence': float(confidence)
                })
        return people

    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×–×™×”×•×™: {e}")
        cv2.imshow('Drone Video - Live Detection', frame)
        cv2.waitKey(1)
        return []


def detect_with_retinanet(frame, model):
    """×–×™×”×•×™ ×¢× RetinaNet (×× ×–××™×Ÿ)"""
    try:
        image = preprocess_image(frame.copy())
        image, scale = resize_image(image)
        boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))
        boxes /= scale

        people = []
        for box, score, label in zip(boxes[0], scores[0], labels[0]):
            if score < CONFIDENCE_THRESHOLD or int(label) != 0:
                continue
            x1, y1, x2, y2 = map(int, box)
            people.append({"bbox": [x1, y1, x2, y2], "confidence": float(score)})
        return people

    except Exception as e:
        print(f"âŒ ×©×’×™××ª RetinaNet: {e}")
        return []


@dataclass
class Frame:
    number: int
    height: float
    longitude: float
    latitude: float


def load_frames_from_excel(file_path: str) -> List[Frame]:
    """×˜×¢×™× ×ª × ×ª×•× ×™ ×¤×¨×™×™××™× ××§×•×‘×¥ Excel ×¢× ×˜×™×¤×•×œ ×‘×©××•×ª ×¢××•×“×•×ª"""
    try:
        print(f"ğŸ“– ×˜×•×¢×Ÿ × ×ª×•× ×™ ××™×§×•× ×-{file_path}...")
        df = pd.read_excel(file_path)

        # ×ª×™×§×•×Ÿ ××•×˜×•××˜×™ ×©×œ ×©×’×™××•×ª ×›×ª×™×‘ × ×¤×•×¦×•×ª
        column_aliases = {
            'longitute': 'longitude',
            'Longitute': 'longitude',
            'Latitude': 'latitude',
            'Altitude': 'altitude',
        }
        df.rename(columns=column_aliases, inplace=True)

        required_columns = ['timestamp', 'altitude', 'longitude', 'latitude']
        missing_columns = [col for col in required_columns if col not in df.columns]

        if missing_columns:
            print(f"âŒ ×¢××•×“×•×ª ×—×¡×¨×•×ª: {missing_columns}")
            print(f"ğŸ“‹ ×¢××•×“×•×ª ×–××™× ×•×ª: {list(df.columns)}")
            return []

        print(f"âœ… × ××¦××• {len(df)} ×©×•×¨×•×ª")

        frames = []
        for index, row in df.iterrows():
            try:
                timestamp_str = str(row['timestamp']).replace('s', '')
                timestamp = float(timestamp_str)
                frame = Frame(
                    number=int(timestamp * 30),  # ×× FPS = 30
                    height=float(row['altitude']),
                    longitude=float(row['longitude']),
                    latitude=float(row['latitude'])
                )
                frames.append(frame)
            except (ValueError, TypeError) as e:
                print(f"âš ï¸ ×©×’×™××” ×‘×©×•×¨×” {index + 1}: {e}")
                continue

        print(f"âœ… ×˜×¢×™× ×” ×”×•×©×œ××”: {len(frames)} ×¤×¨×™×™××™× ×ª×§×™× ×™×")
        return frames

    except FileNotFoundError:
        print(f"âŒ ×§×•×‘×¥ Excel ×œ× × ××¦×: {file_path}")
        return []
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª Excel: {e}")
        return []


def process_video_with_detection(video_path, output_json_path="detection_results.json"):
    """×¢×™×‘×•×“ ×•×™×“××• ×¢× ×–×™×”×•×™ ×”×•×œ×›×™ ×¨×’×œ - ×’×¨×¡×” ××©×•×¤×¨×ª ×¢× ×¡× ×›×¨×•×Ÿ ××™×§×•×"""
    print(f"ğŸ¬ ××¢×‘×“ ×•×™×“××•: {video_path}")

    if not Path(video_path).exists():
        print(f"âŒ ×•×™×“××• ×œ× × ××¦×: {video_path}")
        return False

    # ×‘×“×™×§×ª ×—×™×‘×•×¨ ×œ×©×¨×ª
    if not check_server_connection():
        print("ğŸ’¡ × ×™×ª×Ÿ ×œ×”××©×™×š ×œ×œ× ×©×¨×ª, ××‘×œ ×”× ×ª×•× ×™× ×œ× ×™×™×©××¨×•")
        return False
    else:
        save_to_server = True
        print("ğŸ“Š ××¦×™×’ ×¡×˜×˜×™×¡×˜×™×§×•×ª ×©×¨×ª × ×•×›×—×™×•×ª:")
        get_server_stats()

    # ×˜×¢×™× ×ª × ×ª×•× ×™ ××™×§×•× ××§×•×‘×¥ Excel ×× ×§×™×™×
    location_data = {}
    excel_file = "frames.xlsx"
    if Path(excel_file).exists():
        print(f"ğŸ“ ×˜×•×¢×Ÿ × ×ª×•× ×™ ××™×§×•× ×-{excel_file}...")
        try:
            frames = load_frames_from_excel(excel_file)
            for frame in frames:
                location_data[frame.number] = {
                    'height': frame.height,
                    'longitude': frame.longitude,
                    'latitude': frame.latitude
                }
            print(f"âœ… × ×˜×¢× ×• × ×ª×•× ×™ ××™×§×•× ×¢×‘×•×¨ {len(location_data)} ×¤×¨×™×™××™×")
        except Exception as e:
            print(f"âš ï¸ ×©×’×™××” ×‘×˜×¢×™× ×ª × ×ª×•× ×™ ××™×§×•×: {e}")
            location_data = {}
    else:
        print(f"âš ï¸ ×§×•×‘×¥ {excel_file} ×œ× × ××¦× - ××™×§×•××™× ×™×”×™×• 0")

    # ×˜×¢×™× ×ª ××•×“×œ
    model = None
    if RETINANET_AVAILABLE:
        model_path = find_available_model()
        if model_path:
            try:
                print(f"ğŸ“¥ ×˜×•×¢×Ÿ ××•×“×œ RetinaNet: {model_path}")
                model = load_model(model_path, backbone_name='resnet50')
                print("âœ… ××•×“×œ RetinaNet × ×˜×¢×Ÿ ×‘×”×¦×œ×—×”")
            except Exception as e:
                print(f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª RetinaNet: {e}")
                model = None

    if model is None:
        print("ğŸ”„ ×¢×•×‘×¨ ×œ×–×™×”×•×™ HOG...")
        hog_detector = create_simple_detector()
        detection_method = "HOG"
    else:
        hog_detector = None
        detection_method = "RetinaNet"

    # ×¤×ª×™×—×ª ×•×™×“××•
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("âŒ ×œ× × ×™×ª×Ÿ ×œ×¤×ª×•×— ××ª ×”×•×™×“××•")
        return False

    # ××™×“×¢ ×¢×œ ×”×•×™×“××•
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    duration = total_frames / fps if fps > 0 else 0

    print(f"ğŸ“Š ××™×“×¢ ×¢×œ ×”×•×™×“××•:")
    print(f"   ğŸ¯ ×¨×–×•×œ×•×¦×™×”: {width}x{height}")
    print(f"   â±ï¸ FPS: {fps:.2f}")
    print(f"   ğŸï¸ ×¡×”×´×› ×¤×¨×™×™××™×: {total_frames}")
    print(f"   â° ××©×š: {duration:.1f} ×©× ×™×•×ª")
    print(f"   ğŸ§  ×©×™×˜×ª ×–×™×”×•×™: {detection_method}")

    # ××©×ª× ×™× ×œ×¢×™×‘×•×“
    results = []
    frame_count = 0
    processed_count = 0
    start_time = time.time()
    last_progress_time = start_time
    total_people_detected = 0
    failed_uploads = 0
    frames_with_location = 0

    print("ğŸš€ ×–×™×”×•×™ ×”×—×œ... ×œ×—×¥ ESC ×œ×¢×¦×™×¨×”")

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            frame_count += 1

            # ×‘×“×™×§×ª ESC ×œ×¢×¦×™×¨×”
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC
                print("\nâ¹ï¸ ×¢×¦×™×¨×” ×¢×œ ×¤×™ ×‘×§×©×ª ×”××©×ª××©")
                break

            # ×“×™×œ×•×’ ×¢×œ ×¤×¨×™×™××™×
            if frame_count % SKIP_FRAMES != 0:
                continue

            processed_count += 1

            # ×–×™×”×•×™ ×× ×©×™×
            people = detect_with_retinanet(frame, model) if model else detect_with_hog(frame, hog_detector)
            people_count = len(people)
            total_people_detected += people_count

            # ×§×‘×œ×ª × ×ª×•× ×™ ××™×§×•× ×× ×§×™×™××™×
            location = location_data.get(frame_count, {'height': 0, 'longitude': 0.0, 'latitude': 0.0})

            # ×‘×“×™×§×” ×× ×™×© ××™×§×•× ×ª×§×™×Ÿ
            has_location = location['latitude'] != 0.0 or location['longitude'] != 0.0
            if has_location:
                frames_with_location += 1

            # ×™×¦×™×¨×ª × ×ª×•× ×™ JSON ×œ×¤×¨×™×™×
            timestamp_seconds = round(frame_count / fps, 2) if fps > 0 else frame_count
            frame_data = {
                "frame_number": frame_count,
                "timestamp": timestamp_seconds,
                "pedestrian_count": people_count,
                "time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "video_path": video_path,
                "height": location['height'],
                "longitude": location['longitude'],
                "latitude": location['latitude']
            }

            results.append(frame_data)

            # ×©×œ×™×—×” ×œ×©×¨×ª
            if save_to_server:
                success = create_video_entry(frame_data)
                if not success:
                    failed_uploads += 1

            # ×”×¦×’×ª ×”×ª×§×“××•×ª
            current_time = time.time()
            if current_time - last_progress_time >= 2.0:
                progress = (frame_count / total_frames) * 100 if total_frames > 0 else 0
                elapsed = current_time - start_time
                fps_processing = processed_count / elapsed if elapsed > 0 else 0

                location_info = f"ğŸ“ {frames_with_location}/{processed_count} ×¢× ××™×§×•×" if frames_with_location > 0 else "ğŸ“ ×œ×œ× ××™×§×•×"

                print(f"ğŸ“ˆ Frame {frame_count:,}/{total_frames:,} ({progress:.1f}%) | "
                      f"×–×•×”×• {people_count} ×× ×©×™× | ×¡×”×´×›: {total_people_detected} | "
                      f"××”×™×¨×•×ª: {fps_processing:.1f} FPS | {location_info}")
                last_progress_time = current_time

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ×¢×¦×™×¨×” ×¢×œ ×¤×™ ×‘×§×©×ª ×”××©×ª××© (Ctrl+C)")
    except Exception as e:
        print(f"\nâŒ ×©×’×™××” ×‘×¢×™×‘×•×“: {e}")
    finally:
        cap.release()
        cv2.destroyAllWindows()

    # ×¡×™×›×•× ×¢×™×‘×•×“
    processing_time = time.time() - start_time
    max_people = max((frame['pedestrian_count'] for frame in results), default=0)
    avg_people = total_people_detected / len(results) if results else 0

    print(f"\nğŸ‰ ×¢×™×‘×•×“ ×”×•×©×œ×!")
    print(f"â±ï¸ ×–××Ÿ ×¢×™×‘×•×“: {processing_time:.1f} ×©× ×™×•×ª")
    print(f"ğŸ‘¥ ×¡×”×´×› ×–×™×”×•×™×™×: {total_people_detected}")
    print(f"ğŸ† ××§×¡×™××•× ×‘×¤×¨×™×™×: {max_people}")
    print(f"ğŸ“ˆ ×××•×¦×¢ ×œ×¤×¨×™×™×: {avg_people:.2f}")
    print(f"ğŸï¸ ×¤×¨×™×™××™× ×¢×•×‘×“×•: {len(results)}")
    print(
        f"ğŸ“ ×¤×¨×™×™××™× ×¢× ××™×§×•×: {frames_with_location}/{len(results)} ({frames_with_location / len(results) * 100:.1f}%)")

    if save_to_server:
        success_rate = ((len(results) - failed_uploads) / len(results) * 100) if results else 0
        print(f"ğŸ“¤ ×”×•×¢×œ×• ×œ×©×¨×ª: {len(results) - failed_uploads}/{len(results)} ({success_rate:.1f}%)")

    # ×©××™×¨×ª JSON
    try:
        final_result = {
            "video_info": {
                "path": str(video_path),
                "filename": Path(video_path).name,
                "fps": fps,
                "total_frames": total_frames,
                "resolution": {"width": width, "height": height},
                "detection_method": detection_method,
                "duration_seconds": duration
            },
            "summary": {
                "total_pedestrian_detections": total_people_detected,
                "max_pedestrians_in_frame": max_people,
                "average_pedestrians_per_frame": round(avg_people, 2),
                "processing_time_seconds": round(processing_time, 2),
                "frames_with_location": frames_with_location,
                "location_coverage_percent": round(frames_with_location / len(results) * 100, 1) if results else 0
            },
            "frames": results
        }

        with open(output_json_path, 'w', encoding='utf-8') as f:
            json.dump(final_result, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ JSON × ×©××¨ ×‘: {output_json_path}")
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×©××™×¨×ª JSON: {e}")

    return True


def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª ××©×•×¤×¨×ª ×¢× ×¡× ×›×¨×•×Ÿ ××™×§×•× ××•×˜×•××˜×™"""
    print("ğŸš ×–×™×”×•×™ ×”×•×œ×›×™ ×¨×’×œ ×‘×¡×¨×˜×•× ×™ ×¨×—×¤×Ÿ - ×’×¨×¡×” ××©×•×¤×¨×ª")
    print("=" * 60)

    global video_path
    output_json = "pedestrian_detection_results.json"

    # ×‘×“×™×§×ª ×§×™×•× ×•×™×“××•
    if not Path(video_path).exists():
        print(f"âŒ ×•×™×“××• ×œ× × ××¦×: {video_path}")

        # ×—×™×¤×•×© ×•×™×“××• ××œ×˜×¨× ×˜×™×‘×™
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.m4v']
        found_videos = []
        for ext in video_extensions:
            found_videos.extend(list(Path(".").rglob(f"*{ext}")))

        if found_videos:
            print(f"\nğŸ“ × ××¦××• {len(found_videos)} ×§×‘×¦×™ ×•×™×“××•:")
            for i, video in enumerate(found_videos[:10]):
                size_mb = video.stat().st_size / (1024 * 1024)
                print(f"  {i + 1}. {video} ({size_mb:.1f} MB)")

            try:
                choice = input(f"\nğŸ”¢ ×‘×—×¨ ××¡×¤×¨ ×•×™×“××• (1-{min(len(found_videos), 10)}) ××• Enter ×œ×™×¦×™××”: ").strip()
                if choice.isdigit() and 1 <= int(choice) <= min(len(found_videos), 10):
                    video_path = str(found_videos[int(choice) - 1])
                    print(f"âœ… × ×‘×—×¨: {video_path}")
                else:
                    print("ğŸ‘‹ ×™×•×¦×...")
                    return
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ×™×•×¦×...")
                return
        else:
            print("ğŸ“‚ ×œ× × ××¦××• ×§×‘×¦×™ ×•×™×“××•")
            return

    print(f"\nğŸ¬ ×¢×•×‘×“ ×¢× ×•×™×“××•: {video_path}")

    # ×‘×“×™×§×ª ×§×•×‘×¥ Excel
    excel_file = "frames.xlsx"
    import os
    print(f"ğŸ“ ××—×¤×© ××ª frames.xlsx ×‘×ª×•×š: {os.getcwd()}")

    excel_found = Path(excel_file).exists()

    if excel_found:
        print(f"âœ… × ××¦× ×§×•×‘×¥ ××™×§×•×: {excel_file}")
        print("ğŸ“ ×”××™×§×•××™× ×™×¡×•× ×›×¨× ×• ××•×˜×•××˜×™×ª ×‘××”×œ×š ×”×¢×™×‘×•×“")
    else:
        print(f"âš ï¸ ×§×•×‘×¥ {excel_file} ×œ× × ××¦×")

        # ×—×™×¤×•×© ×§×‘×¦×™ Excel ××œ×˜×¨× ×˜×™×‘×™×™×
        excel_files = list(Path(".").glob("*.xlsx")) + list(Path(".").glob("*.xls"))
        if excel_files:
            print(f"\nğŸ“ × ××¦××• ×§×‘×¦×™ Excel ××œ×˜×¨× ×˜×™×‘×™×™×:")
            for i, file in enumerate(excel_files):
                print(f"  {i + 1}. {file}")

            try:
                choice = input(f"\n×‘×—×¨ ××¡×¤×¨ ×§×•×‘×¥ (1-{len(excel_files)}) ××• Enter ×œ×”××©×™×š ×œ×œ× ××™×§×•×: ").strip()
                if choice.isdigit() and 1 <= int(choice) <= len(excel_files):
                    excel_file = str(excel_files[int(choice) - 1])
                    print(f"âœ… × ×‘×—×¨: {excel_file}")
                    excel_found = True
                else:
                    print("â­ï¸ ×××©×™×š ×œ×œ× × ×ª×•× ×™ ××™×§×•×")
                    excel_found = False
            except KeyboardInterrupt:
                print("\nâ­ï¸ ×××©×™×š ×œ×œ× × ×ª×•× ×™ ××™×§×•×")
                excel_found = False
        else:
            print("ğŸ“‚ ×œ× × ××¦××• ×§×‘×¦×™ Excel - ×××©×™×š ×œ×œ× × ×ª×•× ×™ ××™×§×•×")

    # ×¢×™×‘×•×“ ×•×™×“××• ×¢× ×¡× ×›×¨×•×Ÿ ××™×§×•× ××•×˜×•××˜×™
    print("\n" + "=" * 60)
    print("ğŸ” ××ª×—×™×œ ×¢×™×‘×•×“ ×•×™×“××• ×¢× ×¡× ×›×¨×•×Ÿ ××™×§×•× ××•×˜×•××˜×™")
    print("=" * 60)

   # success = process_video_with_detection(video_path, output_json)
   # success = create_video_entry(video_path, "client/aerial_pedestrian_detection-master/frames.xlsx")
    success = create_video_entry(video_path, os.path.abspath("frames.xlsx"))

    if not success:
        print("\nâŒ ×¢×™×‘×•×“ ×”×•×™×“××• × ×›×©×œ.")
        return

    print("\nâœ… ×¢×™×‘×•×“ ×”×•×™×“××• ×”×•×©×œ× ×‘×”×¦×œ×—×”!")

    # ×”×¦×’×ª ×”×•×¨××•×ª ×¡×™×•×
    print(f"\n" + "=" * 60)
    print("ğŸŠ ×¢×™×‘×•×“ ×”×•×©×œ×!")
    print("=" * 60)
    print("ğŸ“‹ ××” ×œ×¢×©×•×ª ×¢×›×©×™×•:")
    print("1. ğŸ—ºï¸ ×”×¤×¢×œ ××ª ×”××¤×” ×”×“×™× ××™×ª:")
    print("   python dynamic_map.py")
    print("2. ğŸŒ ×’×© ×œ×›×ª×•×‘×ª: http://127.0.0.1:8050")
    print("3. ğŸ“Š ×”××¤×” ×ª×ª×¢×“×›×Ÿ ××•×˜×•××˜×™×ª ×›×œ 5 ×©× ×™×•×ª")

    if excel_found:
        print("4. ğŸ“ ×”××¤×” ×ª×¦×™×’ × ×§×•×“×•×ª ×¢× ××™×§×•× GPS!")
    else:
        print("4. âš ï¸ ×”××¤×” ×ª×¦×™×’ × ×§×•×“×•×ª ×œ×œ× ××™×§×•× (0,0)")
        print("   ğŸ’¡ ×œ×”×•×¡×¤×ª ××™×§×•×: ×”×›×Ÿ ×§×•×‘×¥ frames.xlsx ×•×”×¤×¢×œ ×©×•×‘")

    # ×”×¦×’×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ××—×¨×•× ×•×ª ××”×©×¨×ª
    print(f"\nğŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª ××—×¨×•× ×•×ª ××”×©×¨×ª:")
    final_stats = get_server_stats()

    if final_stats:
        print("ğŸ¯ ×›×œ ×”× ×ª×•× ×™× ××•×›× ×™× ×œ××¤×” ×”×“×™× ××™×ª!")
    else:
        print("âš ï¸ ×œ× × ×™×ª×Ÿ ×œ×§×‘×œ ×¡×˜×˜×™×¡×˜×™×§×•×ª ××”×©×¨×ª")

    print(f"\nğŸ† ×¢×™×‘×•×“ ×”×•×©×œ× ×‘×”×¦×œ×—×”!")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ×ª×•×›× ×™×ª ×”×•×¤×¡×§×” ×¢×œ ×™×“×™ ×”××©×ª××©")
    except Exception as e:
        print(f"\n\nâŒ ×©×’×™××” ×›×œ×œ×™×ª: {e}")
        import traceback

        traceback.print_exc()
    finally:
        print("\nğŸ”š ×¡×™×•× ×ª×•×›× ×™×ª")