import cv2
import numpy as np
import os
from ultralytics import YOLO

# âš™ï¸ ×˜×¢×Ÿ ××ª ××•×“×œ YOLOv8x (××“×•×™×§ ××š ×›×‘×“ â€“ ××ª××™× ×œ×¨×—×¤×Ÿ)
model = YOLO("yolov8x.pt")

input_shape = 1280  # ×¨×–×•×œ×•×¦×™×” ×’×‘×•×”×” ×™×•×ª×¨ ×œ×× ×©×™× ××¨×—×•×§
conf_thresh = 0.25
SKIP_FRAMES = 3

# ğŸ—‚ï¸ ×•×“× ×©×ª×™×§×™×™×ª ×”×¤×œ×˜ ×§×™×™××ª
os.makedirs("results_json", exist_ok=True)

# ğŸ¥ ×¤×ª×— ××ª ×”×¡×¨×˜×•×Ÿ
cap = cv2.VideoCapture("video/video1.mp4")
if not cap.isOpened():
    print("â›” ×œ× × ×™×ª×Ÿ ×œ×¤×ª×•×— ××ª ×”×¡×¨×˜×•×Ÿ"); exit()

frame_count = 0
print("ğŸ¥ ×–×™×”×•×™ ×”×ª×—×™×œ, ×œ×—×¥ 'q' ×›×“×™ ×œ×¦××ª")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame_count += 1
    if frame_count % SKIP_FRAMES != 0:
        continue

    # ğŸ§  ×”×¨×¦×ª ×”××•×“×œ
    results = model.predict(frame, imgsz=input_shape, conf=conf_thresh)[0]

    person_count = 0

    # ğŸ“¦ ×¦×™×•×¨ ×ª×™×‘×•×ª ×¨×§ ×¢×œ ×× ×©×™×
    for box in results.boxes:
        cls_id = int(box.cls[0])
        if cls_id != 0:
            continue  # ××–×”×” ×¨×§ ×× ×©×™×

        person_count += 1
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        conf = float(box.conf[0])
        label = f"Person {conf:.2f}"

        # ğŸ’š ×¨×™×‘×•×¢ ×™×¨×•×§ ×¡×‘×™×‘ ××“×
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, label, (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    # ğŸ§® ×›×ª×•×‘ ××ª ×›××•×ª ×”×× ×©×™× ×¢×œ ×”××¡×š
    cv2.putText(frame, f"People: {person_count}", (20, 40),
                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)

    # ğŸ“ ×©××™×¨×ª JSON
    with open(f"results_json/frame_{frame_count:05d}.json", "w") as f:
        f.write(results.to_json())

    # ğŸ–¼ï¸ ×ª×¦×•×’×” ×—×™×”
    cv2.imshow("YOLOv8 â€“ Drone Person Detection", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
print("âœ… ×¡×™×•×")