from ultralytics import YOLOE
import cv2
import numpy as np


def analyze_video_for_person_stats(video_path, model_path="best.pt", sample_frames=30):
    model = YOLOE("yoloe-11l-seg-pf.pt")
    model.predict()
    cap = cv2.VideoCapture("video/temp2.mp4")
    print("ğŸš€ ××ª×—×™×œ × ×™×ª×•×— ×•×™×“××•...")

    if not cap.isOpened():
        print("â›” ×œ× × ×™×ª×Ÿ ×œ×¤×ª×•×— ××ª ×”×¡×¨×˜×•×Ÿ")
        return

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_area = width * height

    print(f"\nğŸï¸ ×¨×–×•×œ×•×¦×™×™×ª ×”×•×•×™×“××•: {width}x{height} ({frame_area} ×¤×™×§×¡×œ×™× ×¡×”\"×›)")

    person_areas = []
    person_heights = []
    person_widths = []

    frames_processed = 0
    while frames_processed < sample_frames:
        ret, frame = cap.read()
        if not ret:
            break

        results = model.predict(frame, verbose=False)[0]

        for box in results.boxes:
            cls = int(box.cls[0])
            label = results.names[cls].lower()

            if label in ["person", "pedestrian"]:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                w, h = x2 - x1, y2 - y1
                area = w * h
                person_areas.append(area)
                person_widths.append(w)
                person_heights.append(h)

        frames_processed += 1

    cap.release()

    if not person_areas:
        print("âš ï¸ ×œ× ×–×•×”×• ×× ×©×™× ×‘Ö¾30 ×”×¤×¨×™×™××™× ×”×¨××©×•× ×™×")
        return

    # ×—×™×©×•×‘×™× ×¡×˜×˜×™×¡×˜×™×™×
    avg_area = np.mean(person_areas)
    min_area = np.min(person_areas)
    max_area = np.max(person_areas)

    avg_ratio = avg_area / frame_area

    print(f"\nğŸ§â€â™‚ï¸ ×©×˜×— ×××•×¦×¢ ×©×œ ××“×: {int(avg_area)} ×¤×™×§×¡×œ×™×")
    print(f"ğŸ“‰ ×ª×™×‘×” ×”×›×™ ×§×˜× ×”: {min_area:.0f}, ğŸ“ˆ ×”×›×™ ×’×“×•×œ×”: {max_area:.0f}")
    print(f"ğŸ“ ×™×—×¡ ××”×¤×¨×™×™× (×××•×¦×¢): {avg_ratio:.5f}")

    avg_width = np.mean(person_widths)
    avg_height = np.mean(person_heights)
    print(f"\nğŸ“ ×××•×¦×¢ ×’×•×‘×” ××“× ×‘×¤×¨×™×™×: {avg_height:.1f} ×¤×™×§×¡×œ×™×")
    print(f"ğŸ“ ×××•×¦×¢ ×¨×•×—×‘ ××“× ×‘×¤×¨×™×™×: {avg_width:.1f} ×¤×™×§×¡×œ×™×")

    return {
        "resolution": (width, height),
        "frame_area": frame_area,
        "avg_area": avg_area,
        "min_area": min_area,
        "max_area": max_area,
        "avg_ratio": avg_ratio,
        "avg_height": avg_height,
        "avg_width": avg_width
    }

if __name__ == "__main__":
    analyze_video_for_person_stats("C:/Users/USER/Desktop/Ahkathon/video/temp2.mp4", model_path="best.pt")
